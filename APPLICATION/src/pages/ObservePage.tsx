import React, { useCallback, useEffect, useMemo, useState } from 'react';
import { flushSync } from 'react-dom';
import '../style/pages/ObservePage.scss';
import { useNavigate } from 'react-router-dom';
import ObserveCamInfo from '../components/ObserveCamInfo';
import axios from 'axios';
import Api from '../api/Api';
import CreateBtn from '../components/CreateBtn';
import PolygonDraw from '../util/PolygonDraw';
import { Settings } from '@material-ui/icons';
import { useSWRState } from '../fetcher/useSWRState';
import useSWR from 'swr';
import { getFetcher } from '../fetcher/fetcher';

export const camPort1Ip = '192.168.0.3';
export const camPort2Ip = '192.168.0.24';
export const camPort3Ip = '192.168.0.18';
export const camPort4Ip = '192.168.0.30';

type ViedeoFrameType = {
  canvasClass: string;
  frameSrc: string;
  firstCanvas: {
    visible: boolean;
    yellowSensingPercent: number;
    redSensingPercent: number;
    coordinate: Array<any>;
  };
  secondCanvas: {
    visible: boolean;
    yellowSensingPercent: number;
    redSensingPercent: number;
    coordinate: Array<any>;
  };
};

const initVideoFrameData: Array<ViedeoFrameType> = [
  {
    canvasClass: 'polygonCanvas1',
    frameSrc: `http://${camPort1Ip}:81`,
    firstCanvas: {
      visible: true,
      yellowSensingPercent: 1.37,
      redSensingPercent: 0.3,
      coordinate: [
        // [79, 137],
        // [115, 145],
        // [105, 192],
        // [77, 192],
      ],
    },
    secondCanvas: {
      // visible: true,
      visible: false,
      yellowSensingPercent: 0.7,
      redSensingPercent: 0.3,
      coordinate: [
        // [345, 146],
        // [364, 147],
        // [360, 221],
        // [344, 221],
      ],
    },
  },
  {
    canvasClass: 'polygonCanvas2',
    frameSrc: `http://${camPort2Ip}:81`,
    firstCanvas: {
      visible: false,
      yellowSensingPercent: 0.7,
      redSensingPercent: 0.3,
      coordinate: [],
    },
    secondCanvas: {
      visible: false,
      yellowSensingPercent: 0.7,
      redSensingPercent: 0.3,
      coordinate: [],
    },
  },
  {
    canvasClass: 'polygonCanvas3',
    frameSrc: `http://${camPort3Ip}:81`,
    firstCanvas: {
      visible: false,
      yellowSensingPercent: 0.7,
      redSensingPercent: 0.3,
      coordinate: [],
    },
    secondCanvas: {
      visible: false,
      yellowSensingPercent: 0.7,
      redSensingPercent: 0.3,
      coordinate: [],
    },
  },
  {
    canvasClass: 'polygonCanvas4',
    frameSrc: `http://${camPort4Ip}:81`,
    firstCanvas: {
      visible: false,
      yellowSensingPercent: 0.7,
      redSensingPercent: 0.3,
      coordinate: [],
    },
    secondCanvas: {
      visible: false,
      yellowSensingPercent: 0.7,
      redSensingPercent: 0.3,
      coordinate: [],
    },
  },
];

const ObservePage = () => {
  const navigate = useNavigate();
  const polygonDraw = new PolygonDraw();
  const camWidth = 512;
  const camHeight = 384;
  const pointSize = 3; // ë‹¤ê°í˜• ì ì˜ í¬ê¸°
  const lineSize = 2.5; // ë‹¤ê°í˜• ì„ ì˜ êµµê¸°
  const today = new Date().toISOString().slice(0, 10);
  const drawColor = {
    green: '#42f593',
    yellow: '#FFFA7C',
    red: '#FF374B',
  };
  const { data: swrState, mutate: setSwrState } = useSWRState();
  const [txtChangeState, setTxtChangeState] = useState('ë…¹í™”ì‹œì‘');
  const [videoFrameState, setVideoFrameState] =
    useState<Array<ViedeoFrameType>>(initVideoFrameData);

  const [getObserveState, setGetObserveState] = useState([]);

  const [camTabState, setCamTabState] = useState(1);
  const [recordState, setRecordState] = useState(false);
  const findFetcher = (url: string) =>
    axios.post(url, { area: swrState.curTrackerArea }).then((res) => res.data);

  const { data: swrTrackerData, error: swrTrackerErr } = useSWR<
    Array<TrackerObserve>
  >('/api/tracker/find', findFetcher, {
    refreshInterval: 1000,
  });

  // const findFetcher = (url: string) =>
  //   axios
  //     .post(url, {
  //       date: today,
  //       trackerId: swrState.curAreaTrackerId,
  //     })
  //     .then((res) => res.data);
  //
  // const { data: swrObserveData, error } = useSWR<Array<TrackerObserve>>(
  //   '/api/observe/find',
  //   findFetcher,
  //   { refreshInterval: 1000 }
  // );

  const handleActive = (e) => {
    const target = e.currentTarget;
    target.classList.toggle('txtActive');
    target.classList.toggle('hoverCircleActive');
    setTxtChangeState('ë…¹í™”ì¤‘');
  };

  const getStateCoordinate = (arrIndex, itemID) =>
    videoFrameState[arrIndex][itemID].coordinate;

  const setStateCoordinate = (arrIndex, itemID, coordinate) => {
    const newArr = videoFrameState;
    newArr[arrIndex][itemID].coordinate = coordinate;
    flushSync(() => setVideoFrameState([]));
    flushSync(() => setVideoFrameState(newArr));
  };

  const polySort = (arrIndex, itemID) => {
    const coordinate = getStateCoordinate(arrIndex, itemID);
    const centre = [
      coordinate.reduce((sum, p) => sum + p[0], 0) / coordinate.length,
      coordinate.reduce((sum, p) => sum + p[1], 0) / coordinate.length,
    ];
    coordinate.forEach((point) =>
      point.push(...polygonDraw.squaredPolar(point, centre))
    );
    coordinate.sort((a, b) => a[2] - b[2] || a[3] - b[3]);
    coordinate.forEach((point) => (point.length -= 2));
    setStateCoordinate(arrIndex, itemID, coordinate);
  };

  const setNewVideoState = (arrIndex, newSrc) => {
    const newArr = videoFrameState;
    newArr[arrIndex].frameSrc = newSrc;
    flushSync(() => setVideoFrameState([]));
    flushSync(() => setVideoFrameState(newArr));
  };

  const draw = (canvas, clicked = false) => {
    const redCtx = canvas?.getContext('2d');
    const yellowCtx = canvas?.getContext('2d');
    const greenCtx = canvas?.getContext('2d');
    const arrIndex = canvas?.getAttribute('tabIndex');
    const itemID = canvas?.getAttribute('itemID');
    greenCtx?.clearRect(0, 0, canvas.width, canvas.height);

    const { yellowSensingPercent, redSensingPercent, coordinate } =
      videoFrameState[arrIndex][itemID];
    const redSensingPoints = [];
    const yellowSensingPoints = [];
    const greenSensingPoints = [];

    const calibrate = PolygonDraw.getDistanceRate(200, 5);
    console.log('calibrate', calibrate); // 13.2  ,  1më‹¹ 13.2px
    const yellowSetMeter = 1; // 5m
    const yellowDistancePx = calibrate * yellowSetMeter; // 5m = 66px
    const greenSetMeter = 2; // 5m
    const greenDistancePx = calibrate * greenSetMeter; // 5m = 66px

    // ê¸°ì¤€ ì¢Œí‘œì—ì„œ ê° 66pxë§Œí¼ ë” ì»¤ì§„

    /* ë‚´ë¶„ì  êµ¬í•˜ê¸° ê³µì‹ ì°¸ê³  */
    let m1 = yellowSensingPercent;
    let n1 = 1 - m1;
    let m2 = redSensingPercent;
    let n2 = 1 - m2;

    // ë¬´ê²Œì¤‘ì‹¬ì˜ ì¢Œí‘œê°’
    const centerX = polygonDraw.getCentroid(coordinate).x;
    const centerY = polygonDraw.getCentroid(coordinate).y;

    /* ë¬´ê²Œ ì¤‘ì‹ ì°ê¸° */
    PolygonDraw.drawPoints(greenCtx, centerX, centerY, pointSize);

    /* ë‚´ë¶„ì  ì¢Œí‘œ êµ¬í•˜ê¸° */
    const getInsideX = (m, n, x) => (m * x + n * centerX) / (m + n);
    const getInsideY = (m, n, y) => (m * y + n * centerY) / (m + n);

    if (!coordinate.length) return;
    for (const [x, y] of coordinate) {
      /* ë¬´ê²Œì¤‘ì‹¬ê³¼ ê¸°ì¤€ ì¢Œí‘œë“¤ì˜ ê¸¸ì´ */
      const standardLineDistance = PolygonDraw.getTwoPointsDistance(
        [x, y],
        [centerX, centerY]
      );
      // console.log('ë¬´ê²Œì¤‘ì‹¬ê³¼ ê¸°ì¤€ ì¢Œí‘œë“¤ì˜ ê¸¸ì´ ', standardLineDistance);
      // console.log('meter ë¹„ìœ¨ë¡œ ë³€í™˜ëœ ê±°ë¦¬', yellowDistancePx);
      // console.log(
      //   'standardLineDistance + yellowDistancePx',
      //   standardLineDistance + yellowDistancePx
      // );

      /* ê¸°ì¤€ì„  ê±°ë¦¬ì™€ calibrationì—ì„œ êµ¬í•´ì§„ meterë‹¹ px ê°’ì„ ë”í•œê°’ì„ ê¸°ì¤€ì„ ê±°ë¦¬ë¡œ ë‚˜ëˆ„ì–´ ë‚´ë¶„ì ì˜ ë¹„ìœ¨ì„ êµ¬í•œë‹¤. */
      m1 = (standardLineDistance + yellowDistancePx) / standardLineDistance;
      console.log('m1', m1);
      n1 = 1 - m1;

      m2 = (standardLineDistance + greenDistancePx) / standardLineDistance;
      console.log('m2', m2);
      n2 = 1 - m2;

      /* Red Zone ë‹¤ê°í˜•ì  ì°ê¸° */
      redSensingPoints.push([Math.round(x), Math.round(y)]);
      PolygonDraw.drawPoints(redCtx, x, y, pointSize, drawColor.red);

      /* Yellow Zone ë‹¤ê°í˜•ì  ì°ê¸° */
      const yellowInsideX = Math.round(getInsideX(m1, n1, x));
      const yellowInsideY = Math.round(getInsideY(m1, n1, y));
      yellowSensingPoints.push([yellowInsideX, yellowInsideY]);
      PolygonDraw.drawPoints(
        yellowCtx,
        yellowInsideX,
        yellowInsideY,
        pointSize,
        drawColor.yellow
      );

      /* Green Zone ë‹¤ê°í˜•ì  ì°ê¸° */
      const greenInsideX = Math.round(getInsideX(m2, n2, x));
      const greenInsideY = Math.round(getInsideY(m2, n2, y));
      greenSensingPoints.push([greenInsideX, greenInsideY]);
      PolygonDraw.drawPoints(
        greenCtx,
        greenInsideX,
        greenInsideY,
        pointSize,
        drawColor.green
      );
    }

    const redSensingCoordinate = redSensingPoints.join(',');
    const yellowSensingCoordinate = yellowSensingPoints.join(',');
    const greenSensingCoordinate = greenSensingPoints.join(',');

    /* Red Zone ë¼ì¸  ê·¸ë¦¬ê¸° */
    PolygonDraw.drawLines(redCtx, coordinate, lineSize, drawColor.red);
    /* Yellow Zone ë¼ì¸  ê·¸ë¦¬ê¸° */
    PolygonDraw.drawLines(
      yellowCtx,
      yellowSensingPoints,
      lineSize,
      drawColor.yellow
    );
    /* Green Zone ë¼ì¸  ê·¸ë¦¬ê¸° */
    PolygonDraw.drawLines(
      greenCtx,
      greenSensingPoints,
      lineSize,
      drawColor.green
    );

    if (coordinate.length < 3) return;

    let { frameSrc } = videoFrameState[arrIndex];
    if (!clicked) return;

    if (itemID === 'firstCanvas') {
      console.log('firstCanvas');
      frameSrc = `${frameSrc.split(':81')[0]}:81`;
      const newSrc = `${frameSrc}/api/stream/area/1/${yellowSensingCoordinate}/${redSensingCoordinate}/`;
      console.log('newSrc', newSrc);
      setNewVideoState(arrIndex, newSrc);
    } else {
      console.log('secondCanvas');
      const splitedSrc = frameSrc.split('/');
      console.log('splitedSrc', splitedSrc);
      const firstSensingCoord = splitedSrc.slice(7, 9);
      console.log('firstSensingCoord', firstSensingCoord);

      splitedSrc.length = 6;
      splitedSrc.push('2');

      frameSrc = splitedSrc.concat(firstSensingCoord).join('/');
      console.log('frameSrc', frameSrc);
      const newSrc = `${frameSrc}/${yellowSensingCoordinate}/${redSensingCoordinate}`;
      console.log('newSrc', newSrc);
      setNewVideoState(arrIndex, newSrc);
    }
  };

  const canvasClick = (e) => {
    const canvas = e.currentTarget;
    /* Viedeo Frames Array Index */
    const arrIndex = canvas?.getAttribute('tabIndex');
    /* firstCanvas | secondCanvas */
    const itemID = canvas?.getAttribute('itemID');
    const bbox = canvas.getBoundingClientRect(); // viewport ê¸°ì¤€ìœ¼ë¡œ ë‚˜ì˜ ìœ„ì¹˜ ì•Œë ¤ì¤Œ

    // offsetLeft:ì›ì†Œì˜ ì™¼ìª½ ë°”ê¹¥ìª½ í…Œë‘ë¦¬ ì—ì„œ ì› ì†Œ ë¥¼ í¬í•¨ í•˜ ëŠ” ì™¼ìª½ ì•ˆìª½ í…Œë‘ë¦¬ ì‚¬ì´ ì˜ í”½ ì…€ ê±°ë¦¬ ê¹Œì§€ ì… ë‹ˆ ë‹¤.
    // offsetTop:ìš”ì†Œì˜ ìƒë‹¨ ê²½ê³„ì„  ì—ì„œ ìš” ì†Œ ë¥¼ í¬í•¨ í•˜ ëŠ” ìƒë‹¨ ê²½ê³„ì„  ì‚¬ì´ ì˜ í”½ ì…€ ê±°ë¦¬ ê¹Œì§€.
    const x = e.clientX - bbox.left;
    const y = e.clientY - bbox.top;
    const { coordinate } = videoFrameState[arrIndex][itemID];
    console.log('x', x);
    console.log('y', y);

    const match = coordinate?.findIndex(
      ([x0, y0]) => Math.abs(x0 - x) + Math.abs(y0 - y) <= 6
    );
    if (match < 0) coordinate.push([Math.round(x), Math.round(y)]);
    else coordinate.splice(match, 1); // delete point when user clicks near it.
    const newArr = videoFrameState;
    newArr[arrIndex][itemID].coordinate = coordinate;
    flushSync(() => setVideoFrameState([]));
    flushSync(() => setVideoFrameState(newArr));
    flushSync(() => polySort(arrIndex, itemID));
    draw(canvas, true);
  };

  useEffect(() => {
    videoFrameState[0]?.frameSrc &&
      console.log('videoFrameState[0].frameSrc', videoFrameState[0]?.frameSrc);
    videoFrameState[0]?.frameSrc &&
      console.log(
        'videoFrameState[0].firstCanvas.coordinate',
        videoFrameState[0]?.firstCanvas.coordinate
      );
    videoFrameState[0]?.frameSrc &&
      videoFrameState[0]?.firstCanvas.coordinate.forEach((coord) => {
        console.log('coord', coord);
      });

    if (videoFrameState[0]) {
      const coor1 = videoFrameState[0]?.secondCanvas?.coordinate[0];
      const coor2 = videoFrameState[0]?.secondCanvas?.coordinate[1];
      coor1 &&
        coor2 &&
        console.log(
          '2ì°¨ê·¸ë£¹ìœ¼ë¡œ ê±°ë¦¬ì¬ê¸° í™•ì¸',
          PolygonDraw.getTwoPointsDistance(coor1, coor2)
        );
    }

    console.log('rate', PolygonDraw.getDistanceRate(165, 12.5));

    document.querySelectorAll('.polygonCanvas').forEach((ele, idx) => {
      draw(ele);
      // drawCallback(ele);
    });
  }, [videoFrameState]);

  const setProcessedSwrData = () => {
    const processedData = [];
    swrTrackerData.forEach(async (tracker, idx) => {
      await Api.observe
        .findData({
          trackerId: tracker._id,
          date: today,
        })
        .then((observe) => {
          if (observe?.length > 0) {
            const processedObserve = observe.map((obj) => {
              return { ...tracker, ...obj };
            });
            processedData.push(...processedObserve);
            console.log('ğŸŒºğŸŒºğŸŒºprocessedData', processedData);
            flushSync(() => setGetObserveState([...processedData]));
          }
        });
    });
  };

  // useEffect(() => {
  //   console.log(
  //     'swrStateswrStateswrStateswrStateswrStateswrState curTrackerArea',
  //     swrState.curTrackerArea
  //   );
  // }, [swrState]);
  //
  // useEffect(() => {
  //   console.log(
  //     'swrObserveDataswrObserveDataswrObserveDataswrObserveData',
  //     swrObserveData
  //   );
  // }, [swrObserveData]);

  useEffect(() => {
    swrTrackerData?.length > 0 && setProcessedSwrData();
  }, [swrTrackerData]);

  useEffect(() => {
    // console.log('swrTrackerData', swrTrackerData);
    swrTrackerData?.length > 0 && setGetObserveState([]);
  }, [swrTrackerData]);

  useEffect(() => {
    // console.log('ğŸŒ½ğŸŒ½ğŸŒ½ğŸŒ½ğŸŒ½getObserveState', getObserveState);
    if (getObserveState.length === 0) {
      swrTrackerData?.length > 0 && setProcessedSwrData();
    }
  }, [getObserveState]);

  const videoFrameMap = useMemo(() => {
    return videoFrameState.map((data: ViedeoFrameType, idx) => (
      <div className="iframeBox" key={idx}>
        <div className="iframeTitle">
          <span>CAM{(idx + 1).toString()}</span>
          <span className="iframeRecording">
            {/* {camTabState - 1 === idx && recordState && ( */}
            {/*  <div style={{ width: '16px', height: '16px', color: 'red' }}>REC</div> */}
            {/* )} */}
            {camTabState - 1 === idx && recordState && <div>REC</div>}
          </span>
        </div>
        {data.firstCanvas.visible && (
          <canvas
            className={`firstCanvas polygonCanvas ${data.canvasClass}`}
            tabIndex={idx}
            itemID="firstCanvas"
            width={camWidth}
            height={camHeight}
            onClick={canvasClick}
          />
        )}
        {data.secondCanvas.visible && (
          <canvas
            className={`secondCanvas polygonCanvas ${data.canvasClass}`}
            tabIndex={idx}
            itemID="secondCanvas"
            width={camWidth}
            height={camHeight}
            onClick={canvasClick}
          />
        )}
        <iframe
          title="stream1"
          src={
            data.frameSrc.split('/').includes('area')
              ? data.frameSrc
              : `${data.frameSrc}/api/stream/`
          }
          width={camWidth}
          height={camHeight}
        />
      </div>
    ));
  }, [videoFrameState, recordState]);

  const visibilityCamInfo = (e) => {
    const target = e.currentTarget;
    const dType = target.getAttribute('datatype');
    const camTabs = Array.from(document.querySelectorAll('.safetyContents'));
    camTabs.forEach((ele: HTMLElement) => {
      ele.style.display = 'none';
    });
    (
      document.querySelector(
        `#safetyContent${dType}`
      ) as HTMLTableSectionElement
    ).style.display = 'block';

    setCamTabState(parseInt(dType, 10));
  };

  const getTabEles = () => {
    const tabArr = [];
    for (let i = 0; i < 4; i++) {
      tabArr.push(
        <div className="safetyTabBox" key={i}>
          <input
            className="safetyTab"
            id={`safetyTab${i + 1}`}
            datatype={(i + 1).toString()}
            type="radio"
            name="tabs"
            defaultChecked={i === 0 && true}
            onChange={visibilityCamInfo}
          />
          <label className="safeLabel" htmlFor={`safetyTab${i + 1}`}>
            {`Cam${i + 1}`}
          </label>
        </div>
      );
    }
    return tabArr;
  };

  // // ë…¹í™”
  const handleRecordVideo = () => {
    console.log('camTabState', camTabState);
    let ip = null;
    switch (camTabState) {
      case 1:
        ip = camPort1Ip;
        break;
      case 2:
        ip = camPort2Ip;
        break;
      case 3:
        ip = camPort3Ip;
        break;
      case 4:
        ip = camPort4Ip;
        break;
      default:
        ip = camPort1Ip;
    }
    if (!recordState) {
      Api.stream.startRecordVideo(ip);
      setRecordState(true);
    } else {
      Api.stream.stopRecordVideo(ip);
      setRecordState(false);
    }
  };

  return (
    <div id="observeContainer" className="observeContainer">
      <div className="observeLeft">
        <div className="leftBox">
          <div className="titleBox">
            <span className="subTitle">Place</span>
            <span className="mainTitle">{swrState.curTrackerArea}</span>
          </div>
          <div className="safetyTabWrap">
            <div className="safetyTabBox">{getTabEles()}</div>
            <div className="safetyTabContainer">
              <ObserveCamInfo
                videoFrameState={videoFrameState}
                setVideoFrameState={setVideoFrameState}
                camTabState={camTabState}
                recordState={recordState}
                setRecordState={setRecordState}
              />
            </div>
            <div className="bottomBtnBox">
              <div className="recordBtnBox">
                <button className="recordBtn">
                  <div />
                  <div className="hoverCircle" onClick={handleActive} />
                </button>
                <span className="recordTxt">{txtChangeState}</span>
              </div>
              <button
                className="settingBtn"
                onClick={() => {
                  navigate('/detail');
                  // Api.stream
                  //   .stopRecordVideo()
                  //   .catch((err) => console.error(err));
                }}
              >
                <Settings />
              </button>
            </div>
          </div>
        </div>
      </div>
      <div className="observeRight">
        <div className="rightBox">
          {/* ì¹´ë©”ë¼ Observe ë°•ìŠ¤ */}
          <div className="iframeContent">{videoFrameMap}</div>
        </div>
      </div>
    </div>
  );
};

export default ObservePage;
